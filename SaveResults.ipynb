{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SaveResults.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgkODcSAm7RXrW1EKyHqid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunogriep/etm-nas/blob/main/SaveResults.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1gTXJGlqeOM",
        "outputId": "4b461c89-2b23-430e-db9e-d442136168f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# create at 07/03/2022\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench\n",
        "!pip install xautodl\n",
        "\n",
        "!pip install nats-bench\n",
        "!pip install pyyaml==5.4.1\n",
        "!pip install simplejson"
      ],
      "metadata": {
        "id": "s7iQwCz2qfAS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ten5k9f3qnDI",
        "outputId": "dda3377a-5480-4704-f654-f0f105893f14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://brunogriep@bitbucket.org/brunogriep/nas-wot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq6Zrt1eqo66",
        "outputId": "24748a82-00c8-4746-cbc0-c8745fbb3197"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nas-wot'...\n",
            "remote: Enumerating objects: 352, done.\u001b[K\n",
            "remote: Counting objects: 100% (352/352), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 352 (delta 168), reused 277 (delta 116), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (352/352), 931.17 KiB | 3.55 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nas-wot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU-iKt3Rqypg",
        "outputId": "ccf97227-16fa-4a1a-bf8d-0e27d505850e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nas-wot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "'''\n",
        "NATS-Bench for Topology and Size\n",
        "'''\n",
        "!tar xvf /content/drive/MyDrive/Mestrado/Codes/NATS-Bench/NATS-tss-v1_0-3ffb9-simple.tar -C /content/.\n",
        "!tar xvf /content/drive/MyDrive/Mestrado/Codes/NATS-Bench/NATS-sss-v1_0-50262-simple.tar -C /content/.\n",
        "\n",
        "'''\n",
        "CIFAR10, CIFAR100, ImageNet16 datasets\n",
        "# '''\n",
        "# !cp -a /content/drive/MyDrive/Mestrado/Codes/cifar.python/cifar-10-batches-py/. /content/nas-wot/datasets/cifar10\n",
        "# !cp -a /content/drive/MyDrive/Mestrado/Codes/cifar.python/cifar-100-python/. /content/nas-wot/datasets/cifar100\n",
        "# !cp -a /content/drive/MyDrive/Mestrado/Codes/cifar.python/ImageNet16/. /content/nas-wot/datasets/ImageNet16"
      ],
      "metadata": {
        "id": "D133M7D7sga0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports \n",
        "import numpy as np\n",
        "from nasbench import api\n",
        "import random \n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import datasets\n",
        "import nasspace\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from scores import get_score_func\n",
        "from scipy import stats\n",
        "from pycls.models.nas.nas import Cell\n",
        "from os import walk\n",
        "from utils import add_dropout, init_network"
      ],
      "metadata": {
        "id": "_4m6Ya91q4tq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='NAS Without Training')\n",
        "parser.add_argument('--api_loc', default='/content/NATS-sss-v1_0-50262-simple/', type=str, help='path to API')\n",
        "parser.add_argument('--augtype', default='none', type=str, help='which perturbations to use')\n",
        "parser.add_argument('--batch_size', default=128, type=int)\n",
        "parser.add_argument('--data_loc', default='./datasets/cifar10',type=str,help='dataset folder')\n",
        "parser.add_argument('--dataset', default='cifar10', type=str)\n",
        "parser.add_argument('--dropout', action='store_true')\n",
        "parser.add_argument('--GPU', default='0', type=str)\n",
        "parser.add_argument('--init', default='', type=str)\n",
        "parser.add_argument('--maxofn', default=1, type=int, help='score is the max of this many evaluations of the network')\n",
        "parser.add_argument('--n_runs', default=100, type=int)\n",
        "parser.add_argument('--n_samples', default=1000, type=int)\n",
        "parser.add_argument('--nasspace', default='nasbench201',type=str,help='the nas search space to use')\n",
        "parser.add_argument('--num_iter', default=10, type=int)\n",
        "parser.add_argument('--num_labels', default=1,  type=int,help='#classes (nasbench101)')\n",
        "parser.add_argument('--num_modules_per_stack', default=3, type=int,help='#modules per stack (nasbench101)')\n",
        "parser.add_argument('--num_stacks', default=3,  type=int, help='#stacks of modules (nasbench101)')\n",
        "parser.add_argument('--repeat', default=1,type=int, help='how often to repeat a single image with a batch')\n",
        "parser.add_argument('--save_loc', default='results',type=str, help='folder to save results')\n",
        "parser.add_argument('--save_string', default='naswot', type=str, help='prefix of results file')\n",
        "parser.add_argument('--score_type', default='log/mean', type=str)\n",
        "parser.add_argument('--score', default='hook_trace', type=str, help='the score to evaluate')\n",
        "parser.add_argument('--seed', default=1, type=int)\n",
        "parser.add_argument('--sigma', default=0.05 ,type=float, help='noise level if augtype is \"gaussnoise\"')\n",
        "parser.add_argument('--stem_out_channels', default=16, type=int, help='output channels of stem convolution (nasbench101)')\n",
        "parser.add_argument('--trainval', action='store_true')\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.GPU\n",
        "\n",
        "# Reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "5AFjABzKrrbF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.dataset == 'cifar10':\n",
        "  acc_type = 'ori-test'\n",
        "  val_acc_type = 'x-valid'\n",
        "else:\n",
        "  acc_type = 'x-test'\n",
        "  val_acc_type = 'x-valid'\n",
        "args.trainval = True"
      ],
      "metadata": {
        "id": "VT3QDR6wsFQ8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "month = \"march\"\n",
        "mypath = f\"/content/drive/MyDrive/Mestrado/2022/{month}-experiments/\"\n",
        "num_precision = 3\n",
        "filenames = next(walk(mypath), (None, None, []))[2]\n",
        "files = [k for k in filenames if 'random' in k]\n",
        "\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "for file in files:\n",
        "  if \"cifar10\" in file: \n",
        "    args.data_loc = \"./datasets/cifar10\"\n",
        "    args.dataset = \"cifar10\"\n",
        "  elif 'cifar100' in file: \n",
        "    args.data_loc = \"./datasets/cifar100\"\n",
        "    args.dataset = \"cifar100\"\n",
        "  else: \n",
        "    args.dataset = \"ImageNet16-120\"\n",
        "    args.data_loc = \"./datasets/ImageNet16\"\n",
        "\n",
        "  searchspace = nasspace.get_search_space(args)\n",
        "\n",
        "  results = pd.read_csv(mypath + file, sep='\\t', encoding='utf-8')\n",
        "  accs = results[\"accs\"]\n",
        "  chosen = results[\"chosen\"]\n",
        "  scores = results[\"topscores\"]\n",
        "  times = results[\"times\"]\n",
        "  val_accs = []\n",
        "  new_accs = []\n",
        "  count = 0\n",
        "\n",
        "  for uid in chosen:\n",
        "    if uid < 30000:\n",
        "      network = searchspace.get_network(uid)\n",
        "      # if not args.dataset == 'cifar10' or args.trainval:\n",
        "      new_accs.append(searchspace.get_final_accuracy(uid, acc_type, False))\n",
        "      val_accs.append(searchspace.get_final_accuracy(uid, val_acc_type, args.trainval))\n",
        "    else:\n",
        "      count = count + 1\n",
        "\n",
        "  avg_acc = round(np.mean(accs), num_precision)\n",
        "  variance_acc = round(np.var(accs), num_precision)\n",
        "\n",
        "  avg_val_acc = round(np.mean(val_accs), num_precision)\n",
        "  variance_val_acc = round(np.var(val_accs), num_precision)\n",
        "\n",
        "  avg_new_acc = round(np.mean(new_accs), num_precision)\n",
        "  variance_new_acc = round(np.var(new_accs), num_precision)\n",
        "  \n",
        "  avg_time = round(np.mean(times), num_precision)\n",
        "  variance_time = round(np.var(times), num_precision)\n",
        "  median_time =  round(np.median(times), num_precision)\n",
        "  \n",
        "  tau, p = stats.kendalltau(accs, scores)\n",
        "  # new_tau, p = stats.kendalltau(new_accs, scores)\n",
        "\n",
        "  acc_avg_var_str = f\"{avg_acc}±{variance_acc}\"\n",
        "  val_acc_avg_var_str = f\"{avg_val_acc}±{variance_val_acc}\"\n",
        "  new_acc_avg_var_str = f\"{avg_new_acc}±{variance_new_acc}\"\n",
        "\n",
        "  avg_var_str = f\"{avg_time}±{variance_time}\"\n",
        "  avg_str = f\"{avg_time}\"\n",
        "  median_str = f\"{median_time}\"\n",
        "  tau_str = f\"{round(tau, num_precision)}\"\n",
        "  # new_tau_str = f\"{round(new_tau, num_precision)}\"\n",
        "  \n",
        "  df = pd.DataFrame({'Average +- Variance (s)' : avg_var_str,\n",
        "                    'Avg Time (s)' : avg_str,\n",
        "                    'Median Time (s)' : median_str,\n",
        "                    'Accuracy (%)' : acc_avg_var_str,\n",
        "                    'Val Accuracy (%)' : val_acc_avg_var_str,\n",
        "                    'New Accuracy (%)' : new_acc_avg_var_str,\n",
        "                    'Kendal Tau' : tau_str,\n",
        "                    # 'New Kendal Tau' : new_tau_str\n",
        "                     }, index=[0])\n",
        "\n",
        "  df.to_csv(f\"/content/drive/MyDrive/Mestrado/2022/results/{month}/{file}\", sep='\\t', encoding='utf-8')\n",
        "  df2 = pd.concat({f\"{file}\": df})\n",
        "  df_test = pd.concat([df_test, df2])\n",
        "\n",
        "df_test.to_csv(f\"/content/drive/MyDrive/Mestrado/2022/results/{month}/result.csv\", sep='\\t', encoding='utf-8')\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmId-_fOqpRe",
        "outputId": "51a73eb3-3442-403e-db1a-79861df3d564"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  The average squared deviation is normally calculated as\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # Compute the mean.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3724: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ctx = contextlib_nullcontext(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z__5Oi_LuLbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}